{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Key|Value|\n",
    "|:--|:--|\n",
    "|Author|Firas Midani|\n",
    "|E-mail|firas.midani@duke.edu|\n",
    "|Last modified on|2018-02-15|\n",
    "\n",
    "In this notebook, I provide all of the necessary code to reproduce supervised classification in Midani et *al*. (2018) paper titled \"Human gut microbiota predicts suceptibility to *V. cholerae* infection\". In particular, you will be able to run several distinct models by changing only a couple of [model parameters](#Define-model-parameters) for each analysis. In particular, you have the following options:\n",
    "\n",
    "Classification of cholera susceptibility using \n",
    " * known clinical/epidemological risk factors.\n",
    " * relative abundance of OTUs.\n",
    " * presence or absence of OTUs.\n",
    " * both clinical risk factors and relative abundance of OTUs.\n",
    "\n",
    "In this notebook, you can also apply any of these classifications under different schemes: \n",
    "* No cross-validation (`cv = \"NONE\"`)\n",
    "* Hold-out validation (`cv = \"HOV\"`)\n",
    "* Stratified 10-fold cross-validation (`cv = \"SKF\"`)\n",
    "\n",
    "***\n",
    "\n",
    "*For running clinical model, use the following parameters<br/>*\n",
    "* `include_microbe = False`\n",
    "* `include_clinical = True`\n",
    "\n",
    "*For running microbiota model, use the following parameters<br/>*\n",
    "* `include_microbe = True`\n",
    "* `include_clinical = False`\n",
    "\n",
    "*For running combined model, use the following parameters<br/>*\n",
    "* `include_microbe = True`\n",
    "* `include_clinical = True`\n",
    "\n",
    "*For running model on presence or absence of OTUs, use the following parameters<br/>*\n",
    "* `include_microbe = True`\n",
    "* `include_clinical = True`\n",
    "* `binarize_microbes = True`\n",
    "\n",
    "*** \n",
    "\n",
    "In Midani et al. (2018), we focus our analysis on associating microbiomes with cholera susceptibility. In an alternative model, we also run our model on a subset of individuals who are at the early stages of infection. In particular, these individuals were initailly excldued in the study, but later excluded to 16S rRNA gene signatures of *V. cholerae* at their baseline rectal swabs collected at enrollment (day 2). To run this alternative model, change `model_type` form `\"susceptibility\"` to `\"onset\"`\n",
    "\n",
    "\n",
    "*** \n",
    "\n",
    "Notes: Data generated by this notebook may vary slighlty from data/numbers included in the corresponding published article because of different random number seeds. Further, due to high memory requirements, permutation testing (for statistical significance) on these models were performed on HARDAC (High-throughput Applied Research Data Analysis Cluster) which is partially supported by grant 2016-IDG-1013 from the NorthCarolina Biotechnology Center to Duke Center for Genomics and Computational Biology (GCB). This code was modified to communciate with the Slurm Workload Manger accordingly and it is hosted on [Github](https://github.com/LAD-LAB/supervised-classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:52:02.909067Z",
     "start_time": "2018-02-21T14:52:02.875569Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import imp\n",
    "import time \n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_selection  import RFE\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, binarize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print 'pandas\\t\\t%s' % pd.__version__\n",
    "print 'numpy\\t\\t%s' % np.__version__\n",
    "print 'scikit-learn\\t%s' % sk.__version__\n",
    "print 'seaborn\\t\\t%s' % sns.__version__\n",
    "print 'matplotlib\\t%s' % mpl.__version__\n",
    "print \n",
    "\n",
    "RandomSeed = int(np.random.randint(1,10**9))\n",
    "np.random.seed(RandomSeed)\n",
    "print 'random = %s' % RandomSeed\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define user-made functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:52:04.554347Z",
     "start_time": "2018-02-21T14:52:04.242623Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def txt_to_df(filename):\n",
    "    return pd.read_csv(filename,sep='\\t',header=0,index_col=0)\n",
    "\n",
    "def binarizeMicrobes(df):\n",
    "\n",
    "    binary_df = pd.DataFrame(binarize(df),index=df.index,columns=df.keys());\n",
    "\n",
    "    return binary_df\n",
    "\n",
    "def removeRareFeatures(df,threshold=0.10):\n",
    "    \n",
    "    '''\n",
    "    remove features present in less thant percent (threshold) of the samples\n",
    "    '''\n",
    "    \n",
    "    # binarize feature matrix  \n",
    "    binary_df = pd.DataFrame(binarize(df),index=df.index,columns=df.keys());\n",
    "        \n",
    "    # identify prevalent features based on minimum cut-off\n",
    "    minCount = np.ceil(threshold*df.shape[0]);\n",
    "    prevalentFeatures = np.where(binary_df.apply(np.sum)>=minCount)[0];    \n",
    "    prevalentFeatures = df.keys()[prevalentFeatures];\n",
    "    \n",
    "    # reduce feature matrix to prevalent OTUs\n",
    "    df = df.loc[:,prevalentFeatures]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def trasnformFeatureMatrix(df,transformer):\n",
    "    '''\n",
    "    transform all values in dataframe\n",
    "    '''\n",
    "    \n",
    "    return df.apply(transformer)\n",
    "\n",
    "def scaleFeatureMatrix(df,scaler):\n",
    "    '''\n",
    "    scale each feature array in a dataframe\n",
    "    '''\n",
    "    \n",
    "    if isinstance(df,pd.DataFrame):\n",
    "        df = [df];\n",
    "    \n",
    "    df_scale_fit = scaler.fit(df[0]); \n",
    "    \n",
    "    for ii in range(len(df)):\n",
    "        df[ii] = pd.DataFrame(df_scale_fit.transform(df[ii]),\n",
    "                             index=df[ii].index,\n",
    "                             columns=df[ii].keys());\n",
    "    \n",
    "    if len(df)>1:\n",
    "        return df[0],df[1]\n",
    "    else:\n",
    "        return df[0]\n",
    "\n",
    "    \n",
    "def initializeMetricTracker(num_folds,num_resamples):\n",
    "    '''\n",
    "    initialize pandas.DataFrame for tracking area model performance metric (i.e. AuROC)\n",
    "    '''\n",
    "\n",
    "    array_1 = sorted([ii+1 for ii in range(num_resamples)]*num_folds)\n",
    "    array_2 = [ii+1 for ii in range(num_folds)]*num_resamples\n",
    "    arrays = [array_1,array_2]\n",
    "    tuples = list(zip(*arrays))\n",
    "\n",
    "    index = pd.MultiIndex.from_tuples(tuples,names=['Sample','Fold'])\n",
    "\n",
    "    df = pd.DataFrame(columns=index);\n",
    "    df.index.name = 'Rank'\n",
    "\n",
    "    return df\n",
    "\n",
    "def initializeDecTracker(y_all,include_microbes,rfe_n_features_coarse):\n",
    "    '''\n",
    "    initialize pandas.DataFrame for tracking model decision scores on testing set\n",
    "    '''\n",
    "    if include_microbes:\n",
    "        array = ['%s_f' % ii for ii in range(1,rfe_n_features_coarse+1)]\n",
    "    else: \n",
    "        array = '1_f'\n",
    "    df = pd.DataFrame(index=y_all.index,columns=[array])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def initializeCoefTracker(x_all):\n",
    "    '''\n",
    "    initialize pandas.DataFrame for tracking model feature coefficients\n",
    "    '''\n",
    "\n",
    "    df_1 = pd.DataFrame(index=x_all.keys())\n",
    "    df_2 = pd.DataFrame(index=['vbxbase','ageyrs','bloodo'])\n",
    "    df = pd.concat([df_1,df_2])\n",
    "    df.index.name = 'coefficient'\n",
    "\n",
    "    return df\n",
    "\n",
    "def initializeFeatureTable():\n",
    "    '''\n",
    "    initialize pandas.DataFrame for features and their ranks\n",
    "    '''\n",
    "\n",
    "    df = pd.DataFrame(columns=['Feature'])\n",
    "    df.index.name = 'Rank'\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def crossValidationSplit(x_all,y_all,cv,num_folds,RandomSeed):\n",
    "    \n",
    "    '''\n",
    "    define training and testing sets for all folds defined by cv argument\n",
    "    '''\n",
    "\n",
    "    if cv=='HOV':\n",
    "\n",
    "        split_df = y_all.copy()\n",
    "        split_df.loc[:,'color'] = [1 if int(ii.split('.')[1])<=42 else 2 for ii in split_df.index]\n",
    "        \n",
    "        train_index = [x_all.index.get_loc(ii) for ii in split_df[split_df.color==1].index]\n",
    "        test_index = [x_all.index.get_loc(ii) for ii in split_df[split_df.color==2].index]\n",
    "        indices = [(np.array(train_index),np.array(test_index))]\n",
    "        return indices\n",
    "    \n",
    "    elif cv=='SKF':\n",
    "        \n",
    "        SKF = StratifiedKFold(n_splits=num_folds,shuffle=True,random_state=np.random.randint(1,10**9))\n",
    "        return SKF.split(x_all,np.ravel(y_all));\n",
    "    \n",
    "    elif cv=='NONE':\n",
    "        train_index = range(x_all.shape[0]);\n",
    "        test_index = range(x_all.shape[0]);\n",
    "        indices = [(np.array(train_index),np.array(test_index))]\n",
    "        return indices\n",
    "    \n",
    "def extractMaximumPerformance(auc_df):\n",
    "    ''' \n",
    "    in a pandas.DataFrame of single column, find maximum value and its corresponding index\n",
    "    '''\n",
    "    \n",
    "    auc_max = auc_df.max()\n",
    "    auc_index = auc_df.iloc[np.where(auc_df == auc_max)[0]].index[0]\n",
    "    \n",
    "    return auc_max, auc_index\n",
    "\n",
    "def recordPrediction(parent_path,out_df,suffix):\n",
    "    '''\n",
    "    record pandas.DataFrame as CSV file under specific name\n",
    "    '''\n",
    "\n",
    "    if not os.path.exists(parent_path):\n",
    "        os.makedirs(parent_path)\n",
    "    \n",
    "    filename = \"%s/%s.txt\" % (parent_path,suffix);\n",
    "    out_df.to_csv(filename,sep='\\t',header=True,index=True)\n",
    "    \n",
    "def generateUniqueFolderName(argsin):\n",
    "    \n",
    "    model_type,include_microbes,include_clinical,binarize_microbes,cv,num_folds,num_resamples,RandomSeed = argsin\n",
    "    \n",
    "    cv_map = {'NONE':'0','HOV':'1','SKF':2}\n",
    "    \n",
    "    folderName = str([\"S\" if model_type=='susceptibility' else \"O\"][0])\n",
    "    folderName += str([1 if include_microbes else 0][0])\n",
    "    folderName += str([1 if binarize_microbes else 0][0])\n",
    "    folderName += str([1 if include_clinical else 0][0])\n",
    "    folderName += \"_cv%s_\" % cv_map[cv]\n",
    "    folderName += str([\"%s_%s_\" % (num_resamples,num_folds) if cv==\"SKF\" else ''][0])\n",
    "    folderName += str(RandomSeed)\n",
    "    \n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    log = open('jobs_log.txt','a+');\n",
    "    log.write('%s\\t%s\\n' % (st,folderName))\n",
    "\n",
    "    return folderName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:55:35.771895Z",
     "start_time": "2018-02-21T14:55:35.738319Z"
    }
   },
   "outputs": [],
   "source": [
    "## save output\n",
    "save_output = False;\n",
    "\n",
    "## type of model\n",
    "model_type = 'onset' # susceptibility or onset\n",
    "include_microbes = False;\n",
    "include_clinical = True;\n",
    "\n",
    "## use relative abundance (True) or presence/absence only (False)\n",
    "binarize_microbes = False;\n",
    "\n",
    "## feature filtering parameters\n",
    "minPrevalence = 0.10;\n",
    "\n",
    "## feature transformation parameters\n",
    "pseudocount = 1e-6\n",
    "transformer = lambda x: np.log10(x+pseudocount);\n",
    "transformVbx = lambda x: np.log10(x+1);\n",
    "binarizeAge = lambda x: 1 if x>=10 else 0;\n",
    "\n",
    "## feature scaling parameters\n",
    "scaler = StandardScaler()\n",
    "\n",
    "## recursive feature elimination parameters\n",
    "rfe_n_features_coarse = 501;\n",
    "rfe_n_features_fine = 1;\n",
    "rfe_step_coarse = 10;\n",
    "rfe_step_fine = 1;\n",
    "\n",
    "## supervised classification\n",
    "MicrobialClassifier = SVC(kernel = 'linear', C = 100, \n",
    "                          probability = True, shrinking = True,\n",
    "                          cache_size = 2000, random_state = RandomSeed)\n",
    "ClinicalClassifier = LogisticRegression(penalty='l2',C=100,random_state = RandomSeed)\n",
    "\n",
    "## coarse recursive feature elimination\n",
    "CoarseRFE = RFE(estimator = MicrobialClassifier,\n",
    "                n_features_to_select = rfe_n_features_coarse,\n",
    "                step = rfe_step_coarse);\n",
    "\n",
    "## cross-validation scheme\n",
    "cv = 'SKF'\n",
    "\n",
    "## k-fold cross-validation parameters (do not applly for HOV or NONE)\n",
    "num_folds = 10 \n",
    "num_resamples = 30\n",
    "\n",
    "argsin = [model_type,include_microbes,include_clinical,binarize_microbes,cv,num_folds,num_resamples,RandomSeed]\n",
    "\n",
    "## model output \n",
    "parent_path = './output_data/%s'% generateUniqueFolderName(argsin); print parent_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:57:13.798741Z",
     "start_time": "2018-02-21T14:57:13.722626Z"
    }
   },
   "outputs": [],
   "source": [
    "if model_type == 'susceptibility':\n",
    "    \n",
    "    txt_y_all = './input_data/suscpetibility/outcomes.ygbr.day.2.txt';\n",
    "    txt_x_all = './input_data/suscpetibility/otus.ygbr.day.2.txt';\n",
    "    txt_c_all = './input_data/suscpetibility/clinical.ygbr.day.2.txt';\n",
    "\n",
    "elif model_type == 'onset':\n",
    "    \n",
    "    txt_y_all = './input_data/onset/outcomes.infected.batch.1.day.2.txt';\n",
    "    txt_x_all = './input_data/onset/features.S.no.vc.infected.day.2.txt';\n",
    "    txt_c_all = './input_data/onset/clinical.infected.batch.1.day.2.txt';\n",
    "\n",
    "c_all = txt_to_df(txt_c_all);\n",
    "y_all = txt_to_df(txt_y_all);\n",
    "x_all = txt_to_df(txt_x_all);\n",
    "\n",
    "if binarize_microbes==True:\n",
    "    x_all = binarizeMicrobes(x_all)\n",
    "\n",
    "# log-10 transform vbxbase and binarize age based on >=10 y/o threshold\n",
    "c_all.vbxbase = c_all.vbxbase.apply(transformVbx)\n",
    "c_all.ageyrs = c_all.ageyrs.apply(binarizeAge)\n",
    "\n",
    "# make sure data frames are properly ordered\n",
    "x_all = x_all.loc[y_all.index,:]\n",
    "c_all = c_all.loc[y_all.index,:]\n",
    "\n",
    "print c_all.shape\n",
    "print y_all.shape\n",
    "print x_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T15:00:18.636867Z",
     "start_time": "2018-02-21T14:57:14.172058Z"
    }
   },
   "outputs": [],
   "source": [
    "auc_shuffle = [];\n",
    "\n",
    "for ii in range(100):\n",
    "    \n",
    "    print 'permutation #%s' % (ii+1),\n",
    "\n",
    "    np.random.shuffle(y_all.values)\n",
    "\n",
    "    # no need for multiple model instances if not cross-validating\n",
    "    if (cv==\"NONE\") or (cv==\"HOV\"):\n",
    "        num_resamples=1;\n",
    "        num_folds=1;\n",
    "\n",
    "    # initialize tables\n",
    "    auc_df = initializeMetricTracker(num_folds,num_resamples);\n",
    "    dec_df = initializeDecTracker(y_all,include_microbes,rfe_n_features_coarse);\n",
    "    coef_df = initializeCoefTracker(x_all)\n",
    "    features_df = initializeFeatureTable()\n",
    "\n",
    "    # iterate through model instances\n",
    "    for resample_number in range(num_resamples):\n",
    "\n",
    "        #print\n",
    "        #print 'model instance #%s' % (resample_number+1),\n",
    "\n",
    "        # split training/testing sets\n",
    "        cv_splits = crossValidationSplit(x_all,y_all,cv,num_folds,RandomSeed)\n",
    "\n",
    "        # iterate through testing folds\n",
    "        for fold_number,values in enumerate(cv_splits):\n",
    "\n",
    "            #print '.', \n",
    "            # unpack iterator\n",
    "            train_index,test_index = values\n",
    "\n",
    "            # split training and testing \n",
    "            y_train = y_all.iloc[train_index]\n",
    "            y_test = y_all.iloc[test_index]\n",
    "\n",
    "            if include_clinical == True: \n",
    "\n",
    "                # split training and testing \n",
    "                C_train = c_all.iloc[train_index,:]\n",
    "                C_test = c_all.iloc[test_index,:]\n",
    "\n",
    "                # scale feature values to standard normal (into z-scores)\n",
    "                C_train,C_test = scaleFeatureMatrix([C_train,C_test],scaler)\n",
    "\n",
    "            if include_microbes == False:\n",
    "\n",
    "                ## evaluate model performance on selected features\n",
    "                CLF_fit = ClinicalClassifier.fit(C_train,np.ravel(y_train));\n",
    "                CLF_dec = CLF_fit.decision_function(C_test);\n",
    "                CLF_prb = CLF_fit.predict_log_proba(C_test)[:,1];\n",
    "                CLF_auc = roc_auc_score(np.ravel(y_test),CLF_dec);\n",
    "\n",
    "                ## record model performance\n",
    "                auc_df.loc[1,(resample_number+1,fold_number+1)] = CLF_auc;\n",
    "\n",
    "                if (cv==\"NONE\") or (cv==\"HOV\"):\n",
    "                    dec_df.loc[y_test.index,'1_f'] = CLF_dec\n",
    "\n",
    "            elif include_microbes == True:\n",
    "\n",
    "                # split training and testing \n",
    "                X_train = x_all.iloc[train_index,:]\n",
    "                X_test = x_all.iloc[test_index,:]\n",
    "\n",
    "                # remove rare features\n",
    "                X_train = removeRareFeatures(X_train,minPrevalence)\n",
    "                X_test = X_test.loc[:,X_train.keys()]\n",
    "\n",
    "                # logarithmic transform with pseudocount\n",
    "                X_train = trasnformFeatureMatrix(X_train,transformer)\n",
    "                X_test = trasnformFeatureMatrix(X_test,transformer)\n",
    "\n",
    "                # scale feature values to standard normal (into z-scores)\n",
    "                X_train,X_test = scaleFeatureMatrix([X_train,X_test],scaler)\n",
    "\n",
    "                ##############################\n",
    "                ## first stage of coarse rfe\n",
    "                ##############################\n",
    "\n",
    "                RFE1_fit = CoarseRFE.fit(X_train,np.ravel(y_train))\n",
    "                RFE1_support = RFE1_fit.support_\n",
    "\n",
    "                X_train_rfe1_support = X_train.keys()[RFE1_support];\n",
    "                X_train_rfe1 = X_train.loc[:,X_train_rfe1_support];\n",
    "                X_test_rfe1 = X_test.loc[:,X_train_rfe1_support];\n",
    "\n",
    "                ## first stage of coarse rfe\n",
    "                RFE1_fit = CoarseRFE.fit(X_train,np.ravel(y_train))\n",
    "                RFE1_support = RFE1_fit.support_\n",
    "\n",
    "                X_train_rfe1_support = X_train.keys()[RFE1_support];\n",
    "                X_train_rfe1 = X_train.loc[:,X_train_rfe1_support];\n",
    "                X_test_rfe1 = X_test.loc[:,X_train_rfe1_support];\n",
    "\n",
    "                ##############################\n",
    "                ## second stage of fine rfe\n",
    "                ##############################\n",
    "\n",
    "                # initialize feature matrix\n",
    "                X_train_sfe = X_train_rfe1\n",
    "                X_test_sfe = X_test_rfe1\n",
    "\n",
    "                # feature rank from high to low\n",
    "                features_rank = range(X_train_sfe.shape[1])[::-1]#[:-1]\n",
    "\n",
    "                ## in descending fashion\n",
    "                for ii in features_rank:\n",
    "\n",
    "                    # if combiend model, join clinical and microbiota features\n",
    "                    if include_clinical == True:\n",
    "                        X_use_train = X_train_sfe.join(C_train);\n",
    "                        X_use_test = X_test_sfe.join(C_test)\n",
    "                    else:    \n",
    "                        X_use_train = X_train_sfe;\n",
    "                        X_use_test = X_test_sfe;\n",
    "\n",
    "                    ## evaluate model performance on selected features\n",
    "                    CLF_fit = MicrobialClassifier.fit(X_use_train,np.ravel(y_train));\n",
    "                    CLF_dec = CLF_fit.decision_function(X_use_test);\n",
    "                    CLF_auc = roc_auc_score(np.ravel(y_test),CLF_dec);\n",
    "\n",
    "                    if (cv==\"NONE\") or (cv==\"HOV\"):\n",
    "                        dec_df.loc[y_test.index,'%s_f' % (ii+1) ] = CLF_dec\n",
    "\n",
    "                    if (cv==\"NONE\"):\n",
    "                        coef = CLF_fit.coef_[0];\n",
    "                        coef_df.loc[X_use_train.keys(),'%s_f' % (ii+1) ] = coef\n",
    "\n",
    "                    ## record model performance\n",
    "                    auc_df.loc[ii+1,(resample_number+1,fold_number+1)] = CLF_auc;\n",
    "\n",
    "                    ## eliminate next feature\n",
    "                    if X_train_sfe.shape[1]>1: \n",
    "                        SingleRFE = RFE(estimator = MicrobialClassifier,n_features_to_select=ii,step = 1)\n",
    "                        SFE_fit = SingleRFE.fit(X_train_sfe,np.ravel(y_train))\n",
    "                        support = SFE_fit.support_\n",
    "                    else: \n",
    "                        support = np.array([False]);\n",
    "\n",
    "                    ## which feature was removed \n",
    "                    FeaturesKept = X_train_sfe.keys()[support];\n",
    "                    FeatureRemoved = X_train_sfe.keys()[~support].values[0];\n",
    "\n",
    "                    ## reduce feature matrix \n",
    "                    X_train_sfe = X_train_sfe.loc[:,FeaturesKept];\n",
    "                    X_test_sfe = X_test_sfe.loc[:,FeaturesKept];\n",
    "\n",
    "                    ## record removed feature \n",
    "                    if cv=='NONE':\n",
    "                        features_df.loc[ii+1,'Feature'] = FeatureRemoved\n",
    "\n",
    "    ##############################\n",
    "    ## recording model output \n",
    "    ##############################\n",
    "\n",
    "    if save_output == True:\n",
    "\n",
    "        recordPrediction(parent_path,auc_df,'auc_scores')\n",
    "\n",
    "        if (cv==\"NONE\") or (cv==\"HOV\"):\n",
    "            recordPrediction(parent_path,dec_df,'decision_scores')\n",
    "\n",
    "        if (cv==\"NONE\") and (include_microbes==True):\n",
    "            recordPrediction(parent_path,coef_df[coef_df.any(1)],'coefficients')\n",
    "            recordPrediction(parent_path,features_df,'features')    \n",
    "\n",
    "    #print\n",
    "    #print 'Done!'\n",
    "    \n",
    "    print auc_df.mean(1).values[0]\n",
    "    auc_shuffle.append(auc_df.mean(1).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T15:00:18.658472Z",
     "start_time": "2018-02-21T15:00:18.642196Z"
    }
   },
   "outputs": [],
   "source": [
    "auc_df.mean(1).values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T18:16:44.994481Z",
     "start_time": "2018-02-16T18:16:44.990189Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.hist(np.ravel([auc_df[ii].mean(1).values for ii in range(1,31)]));\n",
    "# np.median(np.ravel([auc_df[ii].mean(1).values for ii in range(1,31)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute maximum AuROC (Area under the ROC curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T18:16:45.012666Z",
     "start_time": "2018-02-16T18:16:44.997183Z"
    }
   },
   "outputs": [],
   "source": [
    "auc_df = auc_df[(~auc_df.isnull()).all(1)]\n",
    "    \n",
    "print \n",
    "print 'cv = %s' % cv\n",
    "print \n",
    "print 'include_microbes = %s' % include_microbes\n",
    "print 'binarize_microbes = %s' % binarize_microbes\n",
    "print 'include_clinical = %s' % include_clinical\n",
    "print \n",
    "\n",
    "auc_max, auc_index = extractMaximumPerformance(auc_df.mean(1))\n",
    "print 'Maximum AUC = %0.4f using %i OTUs' % (auc_max, auc_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot AuROC against number of OTUs (if applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T18:16:45.382670Z",
     "start_time": "2018-02-16T18:16:45.015096Z"
    }
   },
   "outputs": [],
   "source": [
    "if include_microbes==True:\n",
    "    fig,ax = plt.subplots(figsize=[5,5])\n",
    "    ax.plot(auc_df.mean(1),lw=4,color=(0.,0.,0.,1.))\n",
    "\n",
    "    ax.set_xlabel('Number of OTUs in model',fontsize=16)\n",
    "    ax.set_ylabel('Area under the ROC curve (AuROC)',fontsize=16)\n",
    "\n",
    "    ax.set_ylim([0.48,1.02])\n",
    "    \n",
    "    # automatically set padding on x-axis based on number of features coarsely selected\n",
    "    if (auc_df.shape[0]%50) < 15:\n",
    "        pad = 0\n",
    "    else:\n",
    "        pad = 1\n",
    "        \n",
    "    xlim_0 = -15\n",
    "    xlim_1 = 50*((auc_df.shape[0]/50)+pad)+15\n",
    "    \n",
    "    ax.set_xlim([xlim_0,xlim_1])\n",
    "\n",
    "    [ii.set(fontsize=16) for ii in ax.get_xticklabels()+ax.get_yticklabels()];\n",
    "    \n",
    "print \n",
    "print 'cv = %s' % cv\n",
    "print \n",
    "print 'include_microbes = %s' % include_microbes\n",
    "print 'binarize_microbes = %s' % binarize_microbes\n",
    "print 'include_clinical = %s' % include_clinical\n",
    "print \n",
    "\n",
    "auc_max, auc_index = extractMaximumPerformance(auc_df.mean(1))\n",
    "print 'Maximum AUC = %0.4f using %i OTUs' % (auc_max, auc_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot ROC curve for optimal model (if applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T18:16:45.434362Z",
     "start_time": "2018-02-16T18:16:45.387397Z"
    }
   },
   "outputs": [],
   "source": [
    "if (cv==\"HOV\"):\n",
    "    \n",
    "    decision_scores = dec_df[dec_df.any(1)]    \n",
    "    decision_scores = decision_scores.iloc[:,(auc_index+0)]\n",
    "    true_labels = y_all.loc[decision_scores.index,:]\n",
    "    tpr,fpr,thresholds = roc_curve(np.ravel(true_labels.values),decision_scores.values)\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=[5,5])\n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='gray',\n",
    "           label='Random guess', alpha=.8)\n",
    "    ax.plot([0]+list(tpr),[0]+list(fpr),lw=8,color='k')\n",
    "\n",
    "    ax.set_xlabel('False Positive Rate',fontsize=16)\n",
    "    ax.set_ylabel('True Positive Rate',fontsize=16)\n",
    "\n",
    "    ax.set_ylim([-0.05,1.05])\n",
    "    ax.set_xlim([-0.05,1.05])\n",
    "\n",
    "    [ii.set(fontsize=16) for ii in ax.get_xticklabels()+ax.get_yticklabels()];\n",
    "    \n",
    "print \n",
    "print 'cv = %s' % cv\n",
    "print \n",
    "print 'include_microbes = %s' % include_microbes\n",
    "print 'binarize_microbes = %s' % binarize_microbes\n",
    "print 'include_clinical = %s' % include_clinical\n",
    "print \n",
    "\n",
    "auc_max, auc_index = extractMaximumPerformance(auc_df.mean(1))\n",
    "print 'Maximum AUC = %0.4f using %i OTUs' % (auc_max, auc_index)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "974px",
    "left": "0px",
    "right": "1637px",
    "top": "107px",
    "width": "283px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
